<h1 align="center">Hi, I'm Akash ğŸ‘‹</h1>
<h3 align="center">AI Engineer â€¢ LLMs â€¢ RAG Systems â€¢ Distributed Training â€¢ Backend & Infra</h3>

<p align="center">
  <a href="https://github.com/akashrai2003"><img src="https://img.shields.io/github/followers/akashrai2003?label=Follow&style=social"></a>
  <a href="mailto:akashtooop@gmail.com"><img src="https://img.shields.io/badge/Email-akashtooop%40gmail.com-red"></a>
  <a href="https://www.linkedin.com/in/akash-rai1701/"><img src="https://img.shields.io/badge/LinkedIn-akashrai-blue?logo=linkedin"></a>
</p>

---

## ğŸš€ About Me  
Iâ€™m an **AI Engineer** who builds **production-grade LLM systems**, **agentic RAG pipelines**, and **scalable backend infra**.  
I love solving complex technical problems using **first principles**, especially involving LLM fine-tuning, retrieval architecture, microservices, and distributed compute.

ğŸ“Œ Experience exclusively in fast-paced **startups, defense-grade projects, and enterprise AI systems**.  
ğŸ“Œ I build products end-to-end: **data â†’ model â†’ backend â†’ deployment**.

---

## ğŸ”¥ What I Work On  
- LLM fine-tuning (Qwen, LLaMA, custom SLMs)  
- High-performance RAG systems (hybrid search, embeddings, ranking)  
- On-prem & cloud LLM inference (microservices, RabbitMQ, MongoDB, MinIO)  
- Agentic workflows using LangChain, LangGraph  
- Distributed training with Horovod, Ray Tune, DDP  
- Optimizing inference: GGUF, GPTQ, AWQ quantization  
- FastAPI, Docker, CI/CD, scalable backend infra  

---

## ğŸ§  Skills & Tools

**AI & ML:**  
`LLMs` â€¢ `RAG` â€¢ `PEFT / LoRA` â€¢ `SFT` â€¢ `Embeddings` â€¢ `Retrieval` â€¢ `Bayesian Optimization` â€¢ `NLP`

**Frameworks:**  
`PyTorch` â€¢ `TensorFlow` â€¢ `FastAPI` â€¢ `LangChain` â€¢ `LangGraph` â€¢ `Diffusers` â€¢ `Ray` â€¢ `Horovod`

**Infra:**  
`Docker` â€¢ `Microservices` â€¢ `Azure` â€¢ `AWS` â€¢ `RabbitMQ` â€¢ `MongoDB` â€¢ `MySQL` â€¢ `MinIO`

**Other:**  
`GitHub Actions` â€¢ `vLLM` â€¢ `FAISS` â€¢ `Vector DBs` â€¢ `EDA`

---

## ğŸ—ï¸ Featured Projects

### ğŸ”¹ **âš¡ Custom Enterprise RAG Platform (10Ã— cheaper than Vectara)**  
Built an end-to-end RAG solution with **hybrid search**, **MySQL metadata filtering**, **FastAPI backend**, and **efficient chunking + embeddings pipeline**. Delivered **10Ã— cost reduction** and improved accuracy.

### ğŸ”¹ **On-Prem LLM Inference Platform (Defense Project)**  
Designed a **5-microservice architecture**: RabbitMQ + MongoDB + MinIO + inference + orchestration. Supports **secure document generation** and **intelligent ingestion** using on-device LLMs.

### ğŸ”¹ **Agentic RAG for Salesforce EinsteinDB**  
Created an AI agent capable of **direct contextual querying** of Salesforce EinsteinDB + automated report generation.

### ğŸ”¹ **Fine-tuned Qwen3-4B for Reasoning**  
Performed SFT on curated reasoning datasets; used **AMD MI300X** + **vLLM** for high-throughput inference.

### ğŸ”¹ **Distributed LLM Training on Azure**  
Used **Horovod, Ray Tune, DDP** on multi-VM clusters + quantized models using **GGUF, AWQ, GPTQ**.

---

## ğŸ“Š GitHub Analytics

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=akashrai2003&show_icons=true&theme=tokyonight" height="180">
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=akashrai2003&layout=compact&theme=tokyonight" height="180">
</p>

<p align="center">
  <img src="https://github-readme-streak-stats.herokuapp.com/?user=akashrai2003&theme=tokyonight" height="180">
</p>

---

## ğŸ† Achievements  
- Built multiple **startup-grade, production-ready AI systems** end-to-end  
- Delivered **10Ã— cost optimization** through custom RAG architecture  
- Contributed to **GSSoC** implementing Bayesian Optimization reducing training time by **40%**  
- Experience working across **defense, enterprise, and early-stage startup AI** ecosystems  

---

## ğŸŒ Connect with Me  
ğŸ“© Email: **akashtooop@gmail.com**  
ğŸ”— LinkedIn: https://www.linkedin.com/in/akash-rai1701  
ğŸ™ GitHub: https://github.com/akashrai2003  

---

â­ *If you like my work, consider starring my repositories!*  
